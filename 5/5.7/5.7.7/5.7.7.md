> [5. T√°cticas](../../5.md) ‚Ä∫ [5.6. Listado Consolidado](../5.6.md) ‚Ä∫ [5.6.7. T√°cticas relacionadas a Otros Atributos](5.6.7.md)

# 5.6.7. T√°cticas relacionadas a Otros Atributos

## M√≥dulo 01: Cat√°logo de Productos

## Escenario 1: Independencia de Base de Datos

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-CP-10 | Portabilidad / Adaptabilidad | Necesidad de migrar de motor de base de datos (ej. de SQL a NoSQL o cambio de proveedor Cloud) | Estrategia Tecnol√≥gica / Optimizaci√≥n de Costos | Capa de Acceso a Datos (Backend) | Tiempo de Mantenimiento / Migraci√≥n | El sistema opera con el nuevo motor de base de datos sin requerir reescritura de la l√≥gica de negocio | Esfuerzo de migraci√≥n < 20 horas-hombre, 0 cambios en l√≥gica de dominio |

- Aplica t√©cnica de **Abstracci√≥n de dependencias / Adaptabilidad ‚Äì S05-2** con las siguientes alternativas:
  1. Desarrollar **C√≥digo dependiente de una sola BD** (Consultas SQL nativas hardcodeadas).
  2. Implementar una **Capa de acceso abstracta (ORM o DAO)**.

### **T√°ctica Elegida**
**Capa de Abstracci√≥n de Datos (ORM / Repository Pattern)**

**Contexto:**
El mercado de tecnolog√≠as de bases de datos evoluciona r√°pidamente. Atarse fuertemente a la sintaxis espec√≠fica de un motor (Vendor Lock-in) representa un riesgo alto si los costos de licencias suben o si los requerimientos de escalabilidad cambian (ej. pasar de datos estructurados en PostgreSQL a datos flexibles en MongoDB).

**Alternativas:**
1. **C√≥digo dependiente (SQL Nativo):**
   - M√°ximo rendimiento te√≥rico.
   - Altamente acoplado: Cambiar de base de datos implica reescribir todas las consultas del sistema.

2. **Capa de acceso abstracta (ORM):**
   - Uso de herramientas como Hibernate, Entity Framework o TypeORM.
   - El c√≥digo manipula objetos, y el ORM traduce a SQL o BSON seg√∫n el driver configurado.

**Criterios de elecci√≥n:**
- **Independencia Tecnol√≥gica:** Capacidad de cambiar la infraestructura sin romper la aplicaci√≥n.
- **Productividad:** Reducci√≥n de c√≥digo repetitivo (CRUD b√°sico).

**Decisi√≥n:**
Se utiliza una capa de abstracci√≥n de datos (ORM).

**Sustento:**
Al implementar un **ORM (Object-Relational Mapping)**, el cat√°logo se vuelve agn√≥stico a la base de datos subyacente. Esto permite, por ejemplo, iniciar el proyecto con **PostgreSQL** por su robustez relacional y migrar f√°cilmente a **MongoDB** si la estructura de los productos se vuelve demasiado variable, realizando cambios √∫nicamente en la configuraci√≥n y no en el c√≥digo fuente del negocio.

---

## M√≥dulo 02: Gesti√≥n de Usuarios

## Escenario 01: Adaptaci√≥n a la Demanda de Tr√°fico

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-GU-13 | Escalabilidad | Aumento repentino de tr√°fico (ej. 10x) en el endpoint de login/validaci√≥n de tokens. | Campa√±a de Marketing / Hora pico de actividad | Pods del Microservicio de Autenticaci√≥n | Producci√≥n | El sistema agrega autom√°ticamente nuevas instancias para repartir la carga y mantener la latencia estable. | Uso de CPU/Latencia < Umbral definido (ej. 70%) |

- Aplica t√©cnica de **Autoescalado de pods de autenticaci√≥n (HPA)** con las siguientes alternativas:
  1. Realizar **Escalado manual** de los servidores.
  2. Implementar **HPA (Horizontal Pod Autoscaler) autom√°tico**.

### **T√°ctica Elegida**
**Horizontal Pod Autoscaler (HPA)**

**Contexto:**
El m√≥dulo de autenticaci√≥n es el primer punto de contacto para cualquier usuario. Un pico de tr√°fico inesperado puede saturar las instancias fijas, provocando errores de inicio de sesi√≥n y ca√≠das del servicio. Se necesita una respuesta el√°stica a la demanda.

**Alternativas:**
1. **Escalado manual:**
   - Lento e ineficiente. Requiere intervenci√≥n humana (DevOps) para reaccionar a la m√©trica de uso del CPU.
   - Resulta en sobreprovisionamiento (costo alto) o infraprovisionamiento (ca√≠das del servicio).

2. **HPA autom√°tico:**
   - La plataforma (Kubernetes) monitorea la carga (CPU/memoria) y a√±ade o elimina instancias de forma autom√°tica.
   - Optimiza el costo y la disponibilidad.

**Criterios de elecci√≥n:**
- **Elasticidad:** Capacidad de respuesta inmediata a la demanda.
- **Eficiencia de Costos:** Pagar solo por los recursos utilizados en un momento dado.
- **Disponibilidad:** Mantener el rendimiento bajo picos de tr√°fico.

**Decisi√≥n:**
Se configur√≥ **Horizontal Pod Autoscaler (HPA)** para equilibrar la carga del m√≥dulo de usuarios. 

**Sustento:**
El **HPA** garantiza que la capa de autenticaci√≥n, que soporta la mayor cantidad de tr√°fico del sistema, pueda **escalar horizontalmente** sin intervenci√≥n manual. Esto asegura la **disponibilidad continua** del proceso de login y mantiene la latencia baja durante los eventos de alta concurrencia.

---

##  M√≥dulo 03: Carrito de Compras y Pedidos

## Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|--------------------|--------------------------|---------------|--------------------------|----------------|---------------|--------------------------|---------------------------|
| ESC-CCP-13 | Escalabilidad | Incremento del 200% en creaci√≥n de pedidos durante evento promocional | Usuarios concurrentes | Backend de Pedidos | Entorno Cloud | El sistema escala autom√°ticamente los recursos y mantiene estabilidad | Escalado < 60 s con 0 ca√≠das |

- Aplica t√©cnica de **Auto Scaling y Microservicios Distribuidos** con las siguientes alternativas:  
  1. Configurar **Kubernetes HPA basado en m√©tricas de CPU y tr√°fico**.  
  2. Implementar **divisi√≥n de servicios (pedidos, carrito, stock)** en pods independientes.

### **T√°ctica Elegida**
**Auto Scaling con Kubernetes HPA**

**Contexto:**  
Los eventos de descuento generan alto volumen de pedidos, lo que requiere que el sistema mantenga rendimiento sin intervenci√≥n manual.

**Alternativas:**  
1. **HPA (Horizontal Pod Autoscaler):**  
   - Escala autom√°ticamente seg√∫n m√©tricas.  
   - Evita sobrecarga de nodos.  

2. **Microservicios Distribuidos:**  
   - Divide las funciones en pods independientes.  
   - Mejora la tolerancia a fallos.  

**Criterios de elecci√≥n:**  
- **Elasticidad:** Escalado din√°mico seg√∫n demanda.  
- **Disponibilidad:** 0 ca√≠das durante picos.  
- **Eficiencia:** Uso √≥ptimo de recursos.  

**Decisi√≥n:**  
HPA (Horizontal Pod Autoscaler).  

**Sustento:**  
Funciona con la estrategia Divide y Vencer√°s al dividir el sistema en pods y luego vencer la sobrecarga mediante la instanciaci√≥n r√°pida de nuevas r√©plicas de los servicios de backend (pedidos) solo cuando las m√©tricas de carga (CPU, tr√°fico) superan un umbral.


---

##  M√≥dulo 04: Sistema de Pagos

## Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|--------------------|--------------------------|---------------|--------------------------|----------------|---------------|--------------------------|---------------------------|
| ESC-SP-013 | Escalabilidad | Incremento repentino de usuarios simult√°neos durante una campa√±a de ventas | Usuarios concurrentes | Backend del M√≥dulo de Pagos | Entorno Cloud | El sistema escala autom√°ticamente los recursos sin afectar el tiempo de respuesta | Tiempo de respuesta < 2 s bajo carga 3x |

- Aplica t√©cnica de **Escalado Horizontal Autom√°tico** con las siguientes alternativas:  
  1. Configurar **Auto Scaling Groups (AWS EC2)**.  
  2. Implementar **contenedores Docker con orquestaci√≥n en Kubernetes**.

### **T√°ctica Elegida**
**Escalado Horizontal Autom√°tico con Kubernetes**

**Contexto:**  
Durante campa√±as o lanzamientos, la carga del sistema puede triplicarse. Se requiere mantener la capacidad de respuesta y estabilidad sin intervenci√≥n manual.

**Alternativas:**  
1. **Auto Scaling Groups (AWS):**  
   - Ajuste din√°mico de instancias EC2 seg√∫n m√©tricas de CPU y tr√°fico.  
   - Integraci√≥n nativa con AWS ELB.  

2. **Kubernetes Horizontal Pod Autoscaler (HPA):**  
   - Escalado autom√°tico de pods en base a consumo de CPU o peticiones.  
   - Mejora la portabilidad y control granular de recursos.  

**Criterios de elecci√≥n:**  
- **Elasticidad:** Aumento o reducci√≥n autom√°tica de nodos.  
- **Disponibilidad:** Cero interrupciones durante el escalado.  
- **Mantenibilidad:** Integraci√≥n con pipelines CI/CD.  

**Decisi√≥n:**  
Kubernetes Horizontal Pod Autoscaler (HPA).  

**Sustento:**  
Esta t√°ctica asegura que el sistema se mantenga estable ante picos de carga, reduciendo costos al escalar solo cuando es necesario.  
Adem√°s, mejora la resiliencia y el control operativo gracias a su integraci√≥n con monitoreo Prometheus y m√©tricas en tiempo real.

---

## M√≥dulo 06: An√°lisis de Datos y Reportes

## Escenario 1: Escalado Bajo Crecimiento de Datos

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-ADR-13 | Escalabilidad | La base de datos anal√≠tica crece exponencialmente (ej. de 10 TB a 50 TB) o hay un pico en el n√∫mero de tareas de procesamiento concurrentes. | Crecimiento de la plataforma GameVault / Tareas de ETL y ML | Data Warehouse / Cluster de Procesamiento | Producci√≥n | El sistema ajusta din√°micamente la capacidad de c√≥mputo y el almacenamiento de forma independiente. | Costo de almacenamiento/TB optimizado en 30% vs. escalado vertical. |

- Aplica t√©cnica de **Escalado El√°stico de Storage/Compute** con las siguientes alternativas:
  1. Utilizar **Escalado vertical (Up-sizing)** (Aumentar la potencia de una sola m√°quina).
  2. Implementar **Separaci√≥n El√°stica de Compute y Storage**.

### **T√°ctica Elegida**
**Separaci√≥n El√°stica de Compute y Storage**

**Contexto:**
El volumen de datos que maneja **GameVault** es impredecible, especialmente con la ingesta de datos retro (im√°genes, metadatos, transacciones). El costo del almacenamiento y la necesidad de c√≥mputo (para los *scripts* de **Python/PySpark**) no crecen al mismo ritmo. La **Escalabilidad** debe ser independiente para optimizar costos.

**Alternativas:**
1. **Escalado vertical (Up-sizing):**
   - Se compra una m√°quina m√°s grande cada vez que se requiere m√°s capacidad.
   - Es costoso e implica *downtime* para la actualizaci√≥n.
   - El almacenamiento y el c√≥mputo est√°n acoplados.

2. **Separaci√≥n El√°stica de Compute y Storage:**
   - El almacenamiento (ej. S3, GCS) es barato y el√°stico.
   - El c√≥mputo (ej. PySpark Cluster) se paga solo cuando se ejecuta el an√°lisis. 
   - Permite escalar el Data Lake de forma ilimitada sin sobrecostos de c√≥mputo inactivo.

**Criterios de elecci√≥n:**
- **Eficiencia de Costos:** Pagar por c√≥mputo solo cuando los *scripts* de **Python** est√°n activos.
- **Capacidad Ilimitada:** Permitir el crecimiento de datos a petabytes sin limitaciones f√≠sicas.
- **Flexibilidad:** Asignar m√°s o menos recursos de c√≥mputo por tarea seg√∫n se necesite.

**Decisi√≥n:**
Se elige la **Separaci√≥n El√°stica de Compute y Storage** (ej. BigQuery/Snowflake) para optimizar el costo y la capacidad.

**Sustento:**
La **Separaci√≥n El√°stica de Compute y Storage** es la clave para la **Escalabilidad** econ√≥mica en un entorno de Big Data moderno. Al desacoplar la capacidad de almacenamiento (barato) de la capacidad de procesamiento (costoso), garantizamos que las tareas de ETL y los modelos de **Python/PySpark** puedan acceder a *datasets* masivos de **GameVault** sin la necesidad de tener servidores de c√≥mputo inactivos y costosos, asegurando que la arquitectura crezca de forma eficiente con la empresa.

---

[‚¨ÖÔ∏è Anterior](../5.6.6/5.6.6.md) | [üè† Home](../../../README.md)