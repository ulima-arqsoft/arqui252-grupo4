> [5. T√°cticas](../../5.md) ‚Ä∫ [5.7. Listado Consolidado](../5.7.md) ‚Ä∫ [5.7.1. T√°cticas de Disponibilidad](5.7.1.md)

# 5.7.1. T√°cticas de Disponibilidad

- [Volver al √≠ndice](/5/5.md)

## M√≥dulo 01: Cat√°logo de Productos

## Escenario 1: Redundancia Activa

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-CP-01 | Disponibilidad | Falla de una zona de disponibilidad o ca√≠da del servidor principal | Infraestructura Cloud / Hardware | M√≥dulo Cat√°logo de Productos | Producci√≥n (Alta Demanda) | El tr√°fico se redirige autom√°ticamente a la r√©plica activa sin interrupci√≥n del servicio | Tiempo de inactividad (Downtime) ‚âà 0 s |

- Aplica t√©cnica de **Redundancia Activa (Hot Spare)** con las siguientes alternativas:
  1. Mantener una **Instancia √∫nica del cat√°logo** (Riesgo de punto √∫nico de falla).
  2. Implementar **R√©plicas activas en la nube** en diferentes zonas de disponibilidad.

### **T√°ctica Elegida**
**Redundancia Activa (Hot Spare) ‚Äì T04-1**

**Contexto:**
El cat√°logo de productos es el punto de entrada principal para los clientes. Si este m√≥dulo falla, los usuarios no pueden ver productos, lo que detiene todo el flujo de ventas. Se requiere disponibilidad continua incluso ante desastres en una zona geogr√°fica.

**Alternativas:**
1. **Instancia √∫nica del cat√°logo:**
   - Menor costo de infraestructura.
   - Alto riesgo: Si el servidor cae, el servicio se detiene totalmente hasta su reinicio.

2. **R√©plicas activas en la nube:**
   - M√∫ltiples instancias procesando tr√°fico simult√°neamente en diferentes zonas.
   - Si una zona cae, las otras asumen la carga instant√°neamente.

**Criterios de elecci√≥n:**
- **Disponibilidad:** Continuidad del negocio 24/7.
- **Resiliencia:** Tolerancia a fallos de hardware o red.
- **Escalabilidad:** Capacidad de distribuir la carga de lectura.

**Decisi√≥n:**
R√©plicas activas en la nube.

**Sustento:**
Al ser el cat√°logo un componente de lectura intensiva y cr√≠tica, la **redundancia activa** asegura que no haya interrupciones en la experiencia del usuario. La inversi√≥n en infraestructura se justifica al prevenir la p√©rdida total de ventas durante una ca√≠da del servidor principal.


## Escenario 2: Monitoreo y Latido (Heartbeat)

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-CP-02 | Disponibilidad / Mantenibilidad | Error interno, excepci√≥n no capturada o latencia elevada | Sistema / Aplicaci√≥n | Monitor de Salud (Health Check) | Producci√≥n | El sistema detecta la anomal√≠a, alerta al equipo y registra el log detallado | Detecci√≥n < 2 s, Reducci√≥n del MTTR |

- Aplica t√©cnica de **Monitor / Latido card√≠aco (Heartbeat)** con las siguientes alternativas:
  1. Realizar un **Monitoreo manual** reactivo (basado en quejas de usuarios).
  2. Implementar un **Sistema autom√°tico (Prometheus/Sentry)** para observabilidad.

### **T√°ctica Elegida**
**Monitor / Latido card√≠aco ‚Äì S04-1**

**Contexto:**
Los errores silenciosos o la degradaci√≥n del rendimiento en el cat√°logo pueden pasar desapercibidos sin herramientas adecuadas, aumentando el tiempo que el sistema pasa en estado fallido (MTTR).

**Alternativas:**
1. **Monitoreo manual:**
   - Depende de reportes de usuarios o revisiones peri√≥dicas del administrador.
   - Tiempo de reacci√≥n muy lento.

2. **Sistema autom√°tico (Prometheus/Sentry):**
   - **Sentry:** Captura excepciones y trazas de errores en tiempo real.
   - **Prometheus:** Recolecta m√©tricas de salud (Heartbeat) y rendimiento.

**Criterios de elecci√≥n:**
- **Tiempo de Recuperaci√≥n:** Necesidad de reducir el MTTR (Mean Time To Repair).
- **Visibilidad:** Diagn√≥stico r√°pido de la causa ra√≠z.
- **Proactividad:** Detectar el fallo antes que el usuario final.

**Decisi√≥n:**
Sistema autom√°tico (Prometheus/Sentry).

**Sustento:**
La integraci√≥n de **Sentry y Prometheus** permite una vigilancia constante ("Latido card√≠aco"). Esto reduce dr√°sticamente el tiempo de reparaci√≥n (‚Üì MTTR) al notificar al equipo t√©cnico exactamente d√≥nde y por qu√© ocurri√≥ el fallo, asegurando que la alta disponibilidad te√≥rica se cumpla en la pr√°ctica.

---

## M√≥dulo 02: Gesti√≥n de Usuarios

## Escenario 1: Estrategia de Autenticaci√≥n

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-GU-01 | Disponibilidad / Seguridad | Solicitud de inicio de sesi√≥n masiva o validaci√≥n de token | Usuario Final / Aplicaci√≥n Cliente | Servicio de Identidad (IdP) | Producci√≥n | El sistema delega la carga de autenticaci√≥n garantizando el acceso sin saturar el backend propio | Uptime garantizado por SLA (99.9%) |

- Aplica t√©cnica de **Integraci√≥n con proveedor externo** con las siguientes alternativas:
  1. Desarrollar una **Autenticaci√≥n interna propia** (JWT, manejo de sesiones y hashing en DB local).
  2. Realizar **Delegaci√≥n a Auth0** (Identity Provider - IdP).

### **T√°ctica Elegida**
**Delegaci√≥n de Autenticaci√≥n (SaaS / Auth0)**

**Contexto:**
La gesti√≥n de usuarios requiere altos est√°ndares de seguridad y disponibilidad. Gestionar credenciales, recuperaci√≥n de contrase√±as y seguridad (MFA) internamente aumenta la complejidad del backend y crea un punto √∫nico de fallo si el servicio de autenticaci√≥n local se satura.

**Alternativas:**
1. **Autenticaci√≥n interna propia:**
   - Control total del c√≥digo.
   - Mayor carga operativa (mantenimiento de servidores, parches de seguridad).
   - Riesgo de ca√≠da ante picos de tr√°fico de login.

2. **Delegaci√≥n a Auth0 (IdP):**
   - Infraestructura gestionada por un tercero especializado.
   - Escalado autom√°tico ante picos de demanda.
   - Cumplimiento de normativas de seguridad por defecto.

**Criterios de elecci√≥n:**
- **Disponibilidad:** Garant√≠a de servicio mediante SLA del proveedor.
- **Seguridad:** Reducci√≥n de superficie de ataque en servidores propios.
- **Time-to-market:** Implementaci√≥n m√°s r√°pida que desarrollar un m√≥dulo de seguridad desde cero.

**Decisi√≥n:**
Delegaci√≥n a Auth0 (IdP).

**Sustento:**
Se opt√≥ por **Auth0** para desacoplar la l√≥gica de autenticaci√≥n del n√∫cleo del negocio. Esto garantiza **alta disponibilidad** (soportada por la infraestructura global de Auth0) y libera al equipo de desarrollo del mantenimiento de seguridad cr√≠tica, permitiendo que el sistema soporte una gran concurrencia de usuarios sin degradar el backend local.


## Escenario 2: Resiliencia de Datos de Usuario

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-GU-02 | Disponibilidad / Tolerancia a Fallos | Ca√≠da completa de un Data Center o Zona de Disponibilidad | Desastre Natural / Falla de Infraestructura Cloud | Base de Datos de Usuarios | Producci√≥n | Los datos de perfil y sesi√≥n siguen accesibles desde una zona secundaria | RPO (P√©rdida de datos) ‚âà 0 |

- Aplica t√©cnica de **Replicaci√≥n de Datos** con las siguientes alternativas:
  1. Mantener una **Replicaci√≥n local** (mismo Data Center).
  2. Configurar **Replicaci√≥n en m√∫ltiples zonas** (Multi-AZ).

### **T√°ctica Elegida**
**Replicaci√≥n en M√∫ltiples Zonas (Multi-AZ)**

**Contexto:**
Los datos de los usuarios son el activo m√°s cr√≠tico. Una ca√≠da del servicio de base de datos que impida leer perfiles o permisos bloquear√≠a el acceso a toda la plataforma, independientemente de si el resto de m√≥dulos funcionan.

**Alternativas:**
1. **Replicaci√≥n local:**
   - Copias de seguridad en el mismo edificio/servidor.
   - Baja latencia de replicaci√≥n.
   - Vulnerable a cortes de energ√≠a o red que afecten al edificio completo.

2. **Replicaci√≥n en m√∫ltiples zonas:**
   - Datos distribuidos en ubicaciones f√≠sicas distintas conectadas por red de baja latencia.
   - Alta resiliencia ante desastres geogr√°ficos o de infraestructura mayor.

**Criterios de elecci√≥n:**
- **Continuidad del Negocio:** El servicio debe sobrevivir a la p√©rdida de un centro de datos.
- **Integridad de Datos:** Minimizar el riesgo de corrupci√≥n o p√©rdida total.

**Decisi√≥n:**
Replicaci√≥n en m√∫ltiples zonas (Multi-AZ).

**Sustento:**
Se eligi√≥ la **replicaci√≥n multizona** para asegurar que la disponibilidad del servicio no est√© ligada a una √∫nica ubicaci√≥n f√≠sica. En caso de fallo en la zona primaria, la base de datos realiza un *failover* autom√°tico a la zona secundaria, permitiendo que los usuarios sigan operando con total normalidad y transparencia.

---

##  M√≥dulo 03: Carrito de Compras y Pedidos

## Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|--------------------|--------------------------|---------------|--------------------------|----------------|---------------|--------------------------|---------------------------|
| ESC-CCP-01 | Disponibilidad | Ca√≠da del microservicio de carrito durante una compra | Servidor Backend | M√≥dulo de Carrito | Producci√≥n | El sistema entra en modo degradado y conserva los productos seleccionados | Recuperaci√≥n autom√°tica < 5 s |

- Aplica t√©cnica de **Redundancia Pasiva (Warm Spare)** con las siguientes alternativas:  
  1. Implementar **heartbeat y monitoreo peri√≥dico para detectar fallas**.  
  2. Configurar **instancia pasiva sincronizada que pueda activarse autom√°ticamente ante una ca√≠da**.

### **T√°ctica Elegida**
**Redundancia Pasiva (Warm Spare)**

**Contexto:**  
El carrito de compras es esencial para las ventas. Una ca√≠da durante la sesi√≥n del usuario podr√≠a implicar p√©rdida de oportunidades de venta y experiencia negativa.

**Alternativas:**  
1. **Heartbeat + Monitoreo:**  
   - Detecta fallos en menos de 3 segundos.  
   - Reinicia el servicio autom√°ticamente.  

2. **Instancia Pasiva Sincronizada:**  
   - Copia activa de datos en tiempo real.  
   - Activaci√≥n inmediata al detectar falla.  

**Criterios de elecci√≥n:**  
- **Disponibilidad:** Recuperaci√≥n <5s.  
- **Costo:** Menor consumo que la redundancia activa.  
- **Simplicidad:** Implementaci√≥n directa en Kubernetes.  

**Decisi√≥n:**  
Instancia Pasiva Sincronizada.  

**Sustento:**  
Proporciona alta disponibilidad sin el costo total de una redundancia activa.  
Garantiza continuidad del servicio en picos de demanda con m√≠nima p√©rdida de datos o interrupciones.

## Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|--------------------|--------------------------|---------------|--------------------------|----------------|--------------|----------------|----------------|
| ESC-CCP-02 | Disponibilidad | Error en base de datos del carrito | Servidor MySQL | Repositorio de Carrito | Producci√≥n | Conmutaci√≥n a base de datos r√©plica | Recuperaci√≥n < 5 s |

**Tipo de decisi√≥n:**  
Estrategia de alta disponibilidad.

**Aplica t√©cnica de Replicaci√≥n Activa con alternativas:**  
1. Replica as√≠ncrona  
2. Replica s√≠ncrona (multi-zona)

### **T√°ctica Elegida**  
**Replicaci√≥n S√≠ncrona (Multi-Zona)**

**Contexto:**  
El carrito almacena temporalmente los productos seleccionados por el usuario. Una falla de base de datos podr√≠a causar p√©rdida de informaci√≥n y abandono de la compra. Se requiere mantener datos disponibles y consistentes en todo momento.

**Alternativas:**

**1. Replica As√≠ncrona:**  
- Sincronizaci√≥n parcial con cierto retardo.  
- Menor consumo de red, pero riesgo de p√©rdida de datos ante fallos s√∫bitos.  

**2. Replica S√≠ncrona Multi-Zona:**  
- Copia exacta en m√∫ltiples regiones de AWS.  
- Cero p√©rdida de datos garantizada.  
- Alta disponibilidad ante cortes regionales.  

**Criterios de elecci√≥n:**  
- **Disponibilidad:** SLA superior al 99.95%.  
- **Integridad:** Datos del carrito deben conservarse intactos.  
- **Recuperaci√≥n:** Failover inmediato sin intervenci√≥n manual.  
- **Costo:** Justificado por la criticidad del proceso.  

**Decisi√≥n:**  
Replicaci√≥n S√≠ncrona Multi-Zona

**Sustento:**  
Esta estrategia asegura que los datos del carrito se mantengan coherentes incluso ante fallos en una zona de disponibilidad. Permite conmutaci√≥n instant√°nea (<5 s) mediante AWS RDS Multi-AZ, garantizando cero p√©rdida de informaci√≥n y manteniendo la experiencia del usuario sin interrupciones perceptibles. Aunque implica un incremento de 25% en costos, su impacto positivo en la confiabilidad y satisfacci√≥n del cliente lo justifica plenamente.

---

##  M√≥dulo 04: Sistema de Pagos

### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|--------------------|--------------------------|--------------|--------------------------|----------------|--------------|----------------|----------------|
| ESC-SP-01 | Disponibilidad | Fallo en el servidor de base de datos principal durante una transacci√≥n | Servidor Cloud | M√≥dulo de Pagos | Operaci√≥n en horario pico | El sistema conmuta autom√°ticamente a una instancia redundante sin afectar la operaci√≥n | 99.9% uptime mensual |

- Aplica t√©cnica de **Redundancia Activa (Hot Spare)** con las siguientes alternativas:
  1. Implementar heartbeat + reintentos
  2. Configurar redundancia activa con instancias paralelas

### **T√°ctica Elegida**
**Redundancia Activa (Hot Spare)**

**Contexto:**  
El m√≥dulo de pagos es cr√≠tico, y cualquier interrupci√≥n afectar√≠a el flujo de transacciones y la confianza del cliente.

**Alternativas:**
1. **Heartbeat + Reintentos:**
   - Monitoreo peri√≥dico cada 5 segundos  
   - Reintentos autom√°ticos antes de escalar la solicitud  
   - Tiempo m√°ximo de recuperaci√≥n: 3 segundos  

2. **Redundancia Activa (Hot Spare):**
   - Instancias activas simult√°neas en diferentes zonas de disponibilidad  
   - Balanceador de carga con health checks cada 10 segundos  
   - Conmutaci√≥n autom√°tica en <500 ms  

**Criterios de elecci√≥n:**
- **Escalabilidad:** Soporte para 1000+ solicitudes concurrentes  
- **Mantenibilidad:** Integraci√≥n con Kubernetes para gesti√≥n automatizada  
- **Transparencia:** Impacto nulo en experiencia de usuario durante fallos  
- **Costo:** Presupuesto aprobado para alta disponibilidad  

**Decisi√≥n:**  
Redundancia Activa (Hot Spare)

**Sustento:**  
La soluci√≥n garantiza continuidad del servicio sin interrupciones perceptibles, cumpliendo con el SLA de 99.9% uptime. Aunque requiere 40% m√°s recursos que la alternativa, justifica la inversi√≥n por el impacto cr√≠tico del m√≥dulo en el core business. La implementaci√≥n con AWS ELB y EC2 Auto Recovery asegura recuperaci√≥n autom√°tica.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|--------------------|--------------------------|--------------|--------------------------|----------------|--------------|----------------|----------------|
| ESC-SP-02 | Disponibilidad | P√©rdida temporal de conexi√≥n con el servicio externo de pagos (PayPal/Yape/Plin) | Servicio Externo | API Gateway | Producci√≥n | El sistema reintenta la conexi√≥n y almacena la transacci√≥n en cola temporal | Recuperaci√≥n exitosa < 10 s |

- Aplica t√©cnica de **Reintentos con Fila de Mensajes (Retry with Message Queue)** con las siguientes alternativas:
  1. Implementar reintentos simples
  2. Implementar RabbitMQ con almacenamiento temporal y reintentos autom√°ticos

### **T√°ctica Elegida**
**Reintentos con Fila de Mensajes (RabbitMQ)**

**Contexto:**  
El sistema depende de servicios externos que pueden sufrir ca√≠das moment√°neas. Se requiere asegurar la persistencia de las transacciones mientras el servicio externo se recupera.

**Alternativas:**
1. **Reintento Simple:**
   - Se intenta la operaci√≥n 3 veces con intervalos de 2 s  
   - No garantiza persistencia si el proceso falla  

2. **RabbitMQ con Reintentos Autom√°ticos:**
   - Persistencia temporal de las transacciones  
   - Reintentos autom√°ticos con backoff exponencial  
   - Log de errores centralizado  

**Criterios de elecci√≥n:**
- **Resiliencia:** Capacidad de recuperaci√≥n ante fallas externas  
- **Consistencia:** Evita p√©rdida de datos transaccionales  
- **Escalabilidad:** Compatible con servicios distribuidos  

**Decisi√≥n:**  
RabbitMQ con Reintentos Autom√°ticos

**Sustento:**  
Mejora la tolerancia a fallos de terceros y asegura la continuidad de las operaciones financieras. Minimiza p√©rdidas de datos y reduce la carga de reenv√≠os manuales.
  
---

##  M√≥dulo 05: Comunidad y Rese√±as
### Escenario 1: Falla del Servicio de Rese√±as

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **ESC-CR-01** | **Disponibilidad** | El servicio de rese√±as deja de responder debido a una sobrecarga en su base de datos. | Falla interna del componente. | Microservicio de Cat√°logo de Juegos (consumidor). | Producci√≥n | La p√°gina de detalle de los juegos carga normalmente, mostrando un mensaje controlado en la secci√≥n de rese√±as en lugar de fallar por completo. | El tiempo de carga de la p√°gina del juego no aumenta m√°s de un 5%. La tasa de error del servicio de Cat√°logo no se ve afectada. |

- Aplica t√©cnica de **Resistir Fallos** con alternativas:
    1.  Llamadas s√≠ncronas sin protecci√≥n.
    2.  Implementaci√≥n del patr√≥n Circuit Breaker.

### T√°ctica Elegida
Patr√≥n de Interruptor de Circuito (Circuit Breaker).

**Contexto:**
El servicio de rese√±as es importante, pero no es cr√≠tico para la funci√≥n principal de vender juegos. Una falla en este servicio secundario no debe impedir que un usuario compre un juego. Se debe evitar una falla en cascada. ‚õìÔ∏è

**Alternativas:**
1.  **Llamadas S√≠ncronas sin Protecci√≥n (F√°cil pero Peligroso):**
    - El servicio de Cat√°logo llama al servicio de Rese√±as y espera una respuesta.
    - Si el servicio de Rese√±as no responde (timeout), el hilo de ejecuci√≥n en el servicio de Cat√°logo se queda bloqueado.
    - **Vulnerabilidad:** M√∫ltiples peticiones concurrentes a p√°ginas de juegos agotar√≠an todos los hilos del servicio de Cat√°logo, provocando su ca√≠da total.

2.  **Implementaci√≥n del Circuit Breaker (Moderada y Elegida):**
    - Se utiliza una librer√≠a como `opossum` (Node.js) para envolver las llamadas al servicio de Rese√±as.
    - Despu√©s de un n√∫mero configurable de fallos, el "circuito se abre" y las llamadas posteriores fallan inmediatamente sin intentar contactar al servicio ca√≠do.
    - Pasado un tiempo, el circuito entra en estado "semiabierto", permitiendo una llamada de prueba para verificar si el servicio se ha recuperado.

**Criterios de elecci√≥n:**
- **Aislamiento de Fallos:** Prevenir que el fallo de un servicio se propague a otros.
- **Recuperaci√≥n R√°pida:** Permitir que el sistema se recupere una vez que el servicio dependiente vuelve a estar en l√≠nea.
- **Experiencia de Usuario:** Ofrecer una experiencia degradada pero funcional en lugar de un error completo.

**Decisi√≥n:**
Implementaci√≥n del patr√≥n Circuit Breaker.

**Sustento:**
El Circuit Breaker es una t√°ctica fundamental para construir sistemas de microservicios resilientes. Protege a los servicios consumidores de fallos en sus dependencias, asegurando que el sistema en su conjunto permanezca disponible y funcional.

---

## M√≥dulo 06: An√°lisis de Datos y Reportes

---

## Escenario 1: Distribuci√≥n de Carga de Consultas

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-ADR-01 | Disponibilidad | Consulta compleja de Big Data (ej. 10 GB) o alto volumen de usuarios de BI concurrentes. | Analista de Negocio / Herramienta de BI | Data Warehouse / Data Lake | Producci√≥n | El sistema distribuye la carga de la consulta a trav√©s de m√∫ltiples nodos para mantener la latencia estable. | Latencia media de reportes clave < 5 segundos. |

- Aplica t√©cnica de **Replicaci√≥n As√≠ncrona (Read Replicas)** con las siguientes alternativas:
  1. Configurar una **R√©plica simple (Pasiva)**.
  2. Implementar **M√∫ltiples R√©plicas de Lectura**.

### **T√°ctica Elegida**
**M√∫ltiples R√©plicas de Lectura**

**Contexto:**
La generaci√≥n de reportes y an√°lisis complejos (OLAP) sobre datos hist√≥ricos y de tendencias retro, es intensiva en I/O. Consultar un √∫nico nodo anal√≠tico satura la fuente de datos y degrada el rendimiento para todos los usuarios. La **Disponibilidad** debe ser alta para la toma de decisiones.

**Alternativas:**
1. **R√©plica simple (Pasiva):**
   - Sirve como backup en caso de falla total, pero no distribuye la carga activa de lectura.
   - Es insuficiente bajo alto tr√°fico concurrente.

2. **M√∫ltiples R√©plicas de Lectura:**
   - Permite que el balanceador de carga dirija las consultas de lectura a cualquiera de las r√©plicas disponibles.
   - Aumenta la capacidad de servicio horizontalmente. 

**Criterios de elecci√≥n:**
- **Disponibilidad:** Asegurar el acceso a los datos anal√≠ticos 24/7 incluso con alta carga.
- **Rendimiento:** Reducir la latencia de las consultas de lectura.
- **Escalabilidad:** Permitir el escalado horizontal seg√∫n el crecimiento de la data hist√≥rica.

**Decisi√≥n:**
Se implementan **M√∫ltiples R√©plicas de Lectura** de la fuente anal√≠tica.

**Sustento:**
La implementaci√≥n de m√∫ltiples r√©plicas es crucial para la **Disponibilidad** en entornos de an√°lisis intensivo. Esto distribuye eficientemente la carga de consultas, protege el nodo principal y garantiza que la capa de BI permanezca accesible y r√°pida, incluso durante el procesamiento de grandes vol√∫menes de datos.


## Escenario 2: Frescura y Confiabilidad de Datos

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-ADR-02 | Disponibilidad | Falla de un script de Python durante la extracci√≥n o transformaci√≥n de datos (ETL). | C√≥digo del Pipeline / Infraestructura Cloud | Pipeline de Ingesta (ETL/ELT) | Producci√≥n | El sistema detecta autom√°ticamente la interrupci√≥n del pipeline y alerta al equipo de datos. | Tiempo medio de detecci√≥n < 5 minutos. |

- Aplica t√©cnica de **Monitoreo de Pipelines** con las siguientes alternativas:
  1. Depender de la **Revisi√≥n manual del estado del script de Python**.
  2. Implementar **Alertas de falla de ETL** (Monitoreo de latido/salud).

### **T√°ctica Elegida**
**Alertas de Falla de ETL**

**Contexto:**
Dado que el m√≥dulo utiliza **Python** para el desarrollo de modelos de datos, si un script falla, los reportes posteriores mostrar√°n datos obsoletos o incompletos. Esto compromete la **Disponibilidad** de datos confiables para la toma de decisiones.

**Alternativas:**
1. **Circuit Breaker en la capa de BI:**
   - Detiene el acceso a reportes si el dato es viejo. Es reactivo.
   - No ayuda a identificar la causa ra√≠z del fallo en el script de Python.

2. **Alertas de falla de ETL:**
   - Es proactivo. Utiliza herramientas como Airflow o un sistema de monitoreo de logs para detectar fallas y alertar autom√°ticamente (ej. a Sentry o Prometheus).

**Criterios de elecci√≥n:**
- **Frescura del Dato:** Reducir el tiempo de reparaci√≥n (MTTR) de los pipelines.
- **Confianza:** Asegurar que los usuarios solo accedan a datos verificados.

**Decisi√≥n:**
Se establecen **Alertas de falla de ETL** para garantizar la frescura de los datos procesados por Python.

**Sustento:**
Establecer alertas autom√°ticas es fundamental para la **Disponibilidad** de datos de calidad. Al detectar inmediatamente la ca√≠da de un script de **Python** o un fallo de conexi√≥n al **Data Lake**, el equipo puede actuar r√°pidamente para restablecer el *pipeline*, garantizando que los reportes de tendencias est√©n siempre actualizados.

---

[üè† Home](../../../README.md) | [Siguiente ‚û°Ô∏è](../5.7.2/5.7.2.md)
