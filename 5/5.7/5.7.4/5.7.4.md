> [5. T√°cticas](../../5.md) ‚Ä∫ [5.7. Listado Consolidado](../5.7.md) ‚Ä∫ [5.7.4. T√°cticas de Rendimiento](5.7.4.md)

# 5.7.4. T√°cticas de Rendimiento

## M√≥dulo 01: Cat√°logo de Productos

## Escenario 1: Estrategia de Cach√©

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-CP-03 | Rendimiento / Eficiencia | Alto volumen de consultas repetitivas (ej. "Juegos de Mario", "Novedades") | Usuarios / Campa√±as de Marketing | Base de Datos / Capa de Cach√© | Producci√≥n (Alta Carga) | El sistema entrega los resultados desde la memoria sin consultar la base de datos principal | Latencia de lectura < 20 ms, Reducci√≥n de carga en BD del 40% |

- Aplica t√©cnica de **Mantener m√∫ltiples copias de datos (almacenamiento en cach√©) ‚Äì S05-1** con las siguientes alternativas:
  1. Consultar siempre la **Base de datos principal** (SQL).
  2. Implementar **Uso de Redis o Elasticsearch como cach√©**.

### **T√°ctica Elegida**
**Cach√© en Memoria (Redis)**

**Contexto:**
El cat√°logo de productos tiene una alta tasa de lectura (muchos usuarios viendo lo mismo) y baja tasa de escritura. Consultar la base de datos relacional para cada petici√≥n de la "Home" o b√∫squedas populares satura el disco y la CPU del servidor de base de datos, degradando el rendimiento general.

**Alternativas:**
1. **Solo base de datos principal:**
   - Simplicidad de arquitectura (una sola fuente de verdad).
   - Cuello de botella r√°pido: A mayor tr√°fico, m√°s lentitud exponencial.

2. **Uso de Redis o Elasticsearch:**
   - **Redis:** Almac√©n de estructura de datos en memoria (Key-Value), extremadamente r√°pido para resultados ya computados.
   - **Elasticsearch:** Motor de b√∫squeda potente, ideal para texto completo, pero requiere m√°s recursos.

**Criterios de elecci√≥n:**
- **Latencia:** Necesidad de tiempos de respuesta sub-milisegundos para navegaci√≥n fluida.
- **Protecci√≥n de Recursos:** Evitar "quemar" la base de datos transaccional con lecturas.

**Decisi√≥n:**
Se implementa Redis para almacenar resultados de b√∫squeda frecuentes.

**Sustento:**
El uso de **Redis** permite interceptar las consultas m√°s comunes antes de que toquen la base de datos. Esto reduce dr√°sticamente la latencia para el usuario final y libera recursos del backend para operaciones m√°s cr√≠ticas (como el checkout). Elasticsearch se reservar√° para b√∫squedas complejas de texto completo si fuera necesario, pero Redis maneja la carga de "Hot Data".


## Escenario 2: Procesamiento de Peticiones

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-CP-04 | Rendimiento / Escalabilidad | Llegada simult√°nea de m√∫ltiples peticiones HTTP al API de cat√°logo | Picos de Tr√°fico (Black Friday / Lanzamientos) | Servidor de Aplicaciones (Backend) | Producci√≥n | El servidor procesa m√∫ltiples solicitudes en paralelo aprovechando los n√∫cleos del CPU | Throughput (RPS) incrementado, Tasa de rechazo baja |

- Aplica t√©cnica de **Introducir concurrencia ‚Äì S05-1** con las siguientes alternativas:
  1. Mantener un **Procesamiento secuencial de peticiones** (Bloqueante).
  2. Implementar **Peticiones concurrentes con hilos o trabajadores**.

### **T√°ctica Elegida**
**Procesamiento Concurrente (Multi-threading / Async)**

**Contexto:**
Si el backend procesa las solicitudes una por una (secuencialmente), una consulta lenta bloquear√≠a a todos los dem√°s usuarios en la cola. En un entorno de comercio electr√≥nico, la capacidad de atender a cientos de clientes a la vez es obligatoria.

**Alternativas:**
1. **Procesamiento secuencial:**
   - F√°cil de depurar.
   - Ineficiente: El CPU espera inactivo durante operaciones de E/S (lectura de disco/red).
   - Alto riesgo de *Timeouts* en el cliente durante picos de tr√°fico.

2. **Peticiones concurrentes:**
   - Uso de **Worker Pools** o modelos as√≠ncronos (Non-blocking I/O).
   - Permite que el servidor atienda nuevas peticiones mientras espera que la base de datos responda a las anteriores.

**Criterios de elecci√≥n:**
- **Throughput:** Maximizar el n√∫mero de solicitudes atendidas por segundo (RPS).
- **Utilizaci√≥n de Recursos:** Aprovechar todos los n√∫cleos del procesador del servidor.

**Decisi√≥n:**
Se habilita el procesamiento concurrente.

**Sustento:**
La concurrencia permite escalar verticalmente el rendimiento del servidor sin a√±adir m√°s hardware inmediato. Al utilizar **hilos o trabajadores (workers)**, el sistema gestiona m√∫ltiples contextos de usuario simult√°neamente, asegurando que el cat√°logo siga respondiendo fluidamente incluso cuando hay cientos de usuarios navegando al mismo tiempo.

---

## M√≥dulo 02: Gesti√≥n de Usuarios

## Escenario 1: Optimizaci√≥n de Sesiones

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-GU-07 | Rendimiento / Escalabilidad | Alto volumen de peticiones que requieren verificaci√≥n de identidad (API Calls) | Usuarios Activos / Frontend | Gestor de Sesiones / Middleware de Auth | Producci√≥n (Alta Concurrencia) | El sistema valida la integridad del token sin realizar consultas costosas a la base de datos relacional | Latencia de validaci√≥n < 5 ms, Carga en BD reducida en 90% |

- Aplica t√©cnica de **Cacheo de sesiones con Redis** con las siguientes alternativas:
  1. Utilizar **Almacenamiento temporal local** (Memoria RAM de la instancia).
  2. Implementar **Distribuci√≥n de Redis Cache**.

### **T√°ctica Elegida**
**Cach√© Distribuida (Redis)**

**Contexto:**
Cada petici√≥n que llega al sistema debe ser autenticada. Si por cada petici√≥n consultamos la tabla de usuarios en la base de datos principal para validar el token o la sesi√≥n, creamos un cuello de botella masivo que degrada el rendimiento de toda la aplicaci√≥n, no solo del login.

**Alternativas:**
1. **Almacenamiento temporal local:**
   - R√°pido, pero los datos no se comparten entre servidores.
   - Obliga a usar "Sticky Sessions" (el usuario debe caer siempre en el mismo servidor), lo cual complica el balanceo de carga.

2. **Distribuci√≥n de Redis Cache:**
   - Almac√©n clave-valor en memoria compartido por todas las instancias.
   - Extremadamente veloz (sub-milisegundos).
   - Permite escalar los servidores backend sin perder el estado de las sesiones.

**Criterios de elecci√≥n:**
- **Latencia:** Necesidad de validar credenciales instant√°neamente.
- **Escalabilidad Horizontal:** El sistema debe soportar agregar m√°s servidores sin problemas de sincronizaci√≥n de sesiones.

**Decisi√≥n:**
Se emplea Redis para acelerar la validaci√≥n.

**Sustento:**
Redis act√∫a como una capa intermedia de ultra-alta velocidad. Al almacenar los tokens activos y sus metadatos en Redis, descargamos casi la totalidad del tr√°fico de lectura de autenticaci√≥n de la base de datos principal, permitiendo que esta se dedique a operaciones de negocio m√°s complejas.


## Escenario 2: Control de Tr√°fico (Rate Limiting)

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-GU-08 | Rendimiento / Seguridad | Intentos reiterados y r√°pidos de inicio de sesi√≥n o recuperaci√≥n de contrase√±a (Brute Force) | Bot / Atacante / Usuario confundido | API Gateway / Controlador de Login | Producci√≥n | El sistema bloquea temporalmente las peticiones excedentes devolviendo un error HTTP 429 (Too Many Requests) | L√≠mite estricto activado tras 5 intentos |

- Aplica t√©cnica de **Limitaci√≥n de tasa** con las siguientes alternativas:
  1. Limitar **Por direcci√≥n IP**.
  2. Limitar **Por usuario o correo electr√≥nico**.

### **T√°ctica Elegida**
**Rate Limit Granular (Por Usuario/Email)**

**Contexto:**
Proteger el endpoint de login es vital para evitar ataques de fuerza bruta y para prevenir que un script sature el servidor de correos (en caso de "Olvid√© mi contrase√±a"). Sin embargo, bloquear usuarios leg√≠timos por error es inaceptable.

**Alternativas:**
1. **Por IP:**
   - Bloquea la direcci√≥n IP de origen.
   - **Problema:** En redes m√≥viles (CGNAT) o oficinas corporativas, cientos de usuarios comparten la misma IP. Bloquear una IP podr√≠a dejar sin servicio a muchos usuarios inocentes.

2. **Por usuario o correo electr√≥nico:**
   - Se rastrea el identificador del recurso (el email que intenta loguearse).
   - Solo se penaliza a la cuenta espec√≠fica que est√° siendo atacada o mal utilizada.

**Criterios de elecci√≥n:**
- **Precisi√≥n:** Evitar "falsos positivos" que afecten a usuarios leg√≠timos (UX).
- **Seguridad:** Mitigar eficazmente el abuso de recursos computacionales.

**Decisi√≥n:**
Se implement√≥ Rate Limit por usuario/email (5 intentos / 5 min).

**Sustento:**
Esta configuraci√≥n protege el sistema y la cuenta del usuario espec√≠ficamente. Al permitir **5 intentos cada 5 minutos**, damos margen a errores humanos (olvido de contrase√±a) sin abrir la puerta a ataques automatizados masivos, manteniendo un equilibrio ideal entre seguridad, rendimiento y experiencia de usuario.

---

##  M√≥dulo 03: Carrito de Compras y Pedidos

## Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|--------------------|--------------------------|---------------|--------------------------|----------------|---------------|--------------------------|---------------------------|
| ESC-CCP-07 | Rendimiento | 200 usuarios a√±aden productos simult√°neamente | Usuarios concurrentes | Backend del Carrito | Horario Pico | Sistema mantiene latencia estable | < 2 s por operaci√≥n |

- Aplica t√©cnica de **Optimizaci√≥n de Lectura/Escritura** con las siguientes alternativas:  
  1. Implementar **Redis Cache para sesiones de usuario**.  
  2. Configurar **Optimizaci√≥n Profunda de la DB** para las tablas del carrito.

### **T√°ctica Elegida**
**Optimizaci√≥n de Lectura/Escritura**

**Contexto:**  
Durante campa√±as, m√∫ltiples usuarios realizan modificaciones simult√°neas al carrito, generando carga en la base de datos.

**Alternativas:**  
1. **Redis Cache:**  
   - Guarda temporalmente los carritos activos.  
   - Reduce consultas repetitivas.  

2. **Optimizaci√≥n de la DB :**  
   - Crea √≠ndices compuestos y espec√≠ficos para las consultas de carrito por ID de usuario y sesi√≥n.  
   - Aplica sharding o particionamiento a la tabla del carrito para distribuir f√≠sicamente los datos.  

**Criterios de elecci√≥n:**  
- **Rendimiento:** Mantener respuesta <2 s.  
- **Eficiencia:** Reducci√≥n de consultas redundantes.  
- **Consistencia:** Sin p√©rdida de datos.  

**Decisi√≥n:**  
Redis Cache .  

**Sustento:**  
Soluci√≥n m√°s efectiva para el est√≠mulo de concurrencia intensa y necesidad de baja latencia. Aplica el principio de Divide y Vencer√°s aislando las costosas operaciones de lectura en una capa ultrarr√°pida (memoria), garantizando que el sistema pueda manejar los 200 usuarios simult√°neos y mantener la latencia cr√≠tica por debajo de 2 segundos. 

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|--------------------|--------------------------|---------------|--------------------------|----------------|--------------|----------------|----------------|
| ESC-CCP-08 | Rendimiento | Consultas masivas de historial de pedidos | Usuarios y Admin | Servicio de historial | Producci√≥n | Respuestas paginadas y cacheadas | Tiempo de respuesta < 1.5 s |

**Aplica t√©cnica de Paginaci√≥n y Caching con alternativas:**  
1. Consultas directas a base de datos.  
2. Paginaci√≥n + almacenamiento temporal en memoria (Redis).

### **T√°ctica Elegida**
**Paginaci√≥n + Caching**

**Contexto:**  
El historial de pedidos puede ser muy grande, afectando rendimiento del sistema si se consultan todos los registros a la vez.

**Alternativas:**

**1. Consultas directas:**  
- Acceso completo a la base de datos.  
- Riesgo de latencia alta y bloqueo.  

**2. Paginaci√≥n + Caching:**  
- Se divide la respuesta en bloques.  
- Cache temporal de p√°ginas visitadas.  

**Criterios:**  
- Velocidad de consulta.  
- Escalabilidad ante gran cantidad de usuarios.  
- Uso eficiente de memoria.  

**Decisi√≥n:**  
Paginaci√≥n + Caching.

**Sustento:**  
Permite manejar historiales extensos sin afectar la experiencia del usuario, garantizando consultas r√°pidas y evitando sobrecarga en la base de datos.

---

##  M√≥dulo 04: Sistema de Pagos

## Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|--------------------|--------------------------|---------------|--------------------------|----------------|---------------|--------------------------|---------------------------|
| ESC-SP-07 | Rendimiento | Aumento de 300% en solicitudes simult√°neas | Usuarios concurrentes | Backend de Pagos | Horario Pico | Sistema mantiene tiempos de respuesta estables | < 2 s promedio de respuesta |

- Aplica t√©cnica de **Caching y Balanceo de Carga** con las siguientes alternativas:  
  1. Implementar **Redis Cache** para peticiones repetitivas.  
  2. Configurar **Load Balancer (AWS ELB)**.

### **T√°ctica Elegida**
**Caching y Balanceo de Carga**

**Contexto:**  
Durante campa√±as promocionales, el tr√°fico puede triplicarse. Las operaciones deben mantenerse estables sin afectar los tiempos de pago.

**Alternativas:**  
1. **Redis Cache:**  
   - Almacena respuestas frecuentes.  
   - Reduce carga del backend.  

2. **Load Balancer:**  
   - Distribuye tr√°fico entre m√∫ltiples instancias activas.  
   - Monitoreo en tiempo real.  

**Criterios de elecci√≥n:**  
- **Escalabilidad:** Tolerar m√°s de 2000 solicitudes concurrentes.  
- **Rendimiento:** Tiempos <2s por transacci√≥n.  
- **Costo:** Ajuste din√°mico de instancias.  

**Decisi√≥n:**  
Load Balancer.

**Sustento:**  
Esto garantiza que el sistema pueda escalar eficientemente agregando m√°s instancias bajo el Balanceador, absorbiendo el pico de tr√°fico y manteniendo los tiempos de respuesta estables por debajo de 2 segundos sin sobrecargar ning√∫n recurso individual.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|------------------|------------------------|--------------|------------------------|---------------|-------------|----------------|----------------|
| ESC-SP-08 | Rendimiento | Picos de transacciones por eventos especiales | Usuarios y promociones | Servicio de pagos | Producci√≥n | Escalado autom√°tico y tiempos estables | < 1.8 s promedio por transacci√≥n |

**Aplica t√©cnica de Autoescalado con alternativas:**  
1. Escalado manual de instancias.  
2. Autoescalado basado en m√©tricas de CPU y tr√°fico.

### **T√°ctica Elegida**
**Autoescalado en la nube**

**Contexto:**  
Durante eventos como Black Friday, el sistema debe aumentar autom√°ticamente su capacidad para mantener rendimiento sin intervenci√≥n humana.

**Alternativas:**

**1. Escalado manual:**  
- Riesgo de retraso y saturaci√≥n en picos inesperados.  

**2. Autoescalado:**  
- Instancias adicionales activadas autom√°ticamente seg√∫n m√©tricas.  

**Criterios:**  
- Escalabilidad inmediata  
- Continuidad del servicio  
- Costo eficiente de recursos  

**Decisi√≥n:**  
Autoescalado

**Sustento:**  
Garantiza que el m√≥dulo de pagos soporte altos vol√∫menes de transacciones sin afectar SLA, optimizando costos de infraestructura y asegurando experiencia del usuario.


##  M√≥dulo 05: Comunidad y Rese√±as
### Escenario 1: Carga Lenta de P√°gina con Muchas Rese√±as 

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **ESC-CR-04** | **Rendimiento** | Un usuario carga la p√°gina de un juego popular con m√°s de 4,000 rese√±as. | Usuario leg√≠timo. | API de Rese√±as y Frontend. | Operaci√≥n Normal | La p√°gina carga r√°pidamente, mostrando la informaci√≥n principal del juego y el primer "lote" de rese√±as. El resto se carga bajo demanda. | El tiempo de carga inicial de la p√°gina (LCP) es < 2.5 segundos. La consulta a la base de datos para obtener las rese√±as tarda < 100ms. |

- Aplica t√©cnica de **Gestionar Recursos** con alternativas:
    1.  Cargar todas las rese√±as en una sola petici√≥n.
    2.  Paginaci√≥n de datos en la API y almacenamiento en cach√© de datos agregados.

### T√°ctica Elegida
Paginaci√≥n de Datos en la API + Caching de Datos Agregados con Redis.

**Contexto:**
Cargar miles de registros de una base de datos en una sola consulta es ineficiente, lento y puede sobrecargar tanto el servidor como el navegador del cliente. La experiencia del usuario se ve directamente afectada por tiempos de carga prolongados. üê¢

**Alternativas:**
1.  **Cargar Todo de una Vez (F√°cil pero Ineficiente):**
    - El endpoint `GET /reviews` devuelve un JSON con las 4,000 rese√±as.
    - **Vulnerabilidad:** La consulta a la base de datos es extremadamente lenta. La transferencia de datos consume mucho ancho de banda. El navegador puede congelarse al intentar renderizar tantos elementos.

2.  **Paginaci√≥n y Cach√© (Moderada y Elegida):**
    - La API implementa **paginaci√≥n (f√°cil)**, devolviendo las rese√±as en lotes (ej. `GET /reviews?page=1&limit=20`). Los frameworks y ORMs modernos facilitan enormemente esta tarea.
    - Se implementa una **cach√© con Redis (moderado)** para almacenar datos agregados que se calculan con frecuencia, como la calificaci√≥n promedio y el n√∫mero total de rese√±as, evitando consultas costosas en cada carga de p√°gina.

**Criterios de elecci√≥n:**
- **Latencia:** Minimizar el tiempo de carga inicial para el usuario.
- **Eficiencia de Recursos:** Reducir la carga en la base de datos y el consumo de ancho de banda.
- **Experiencia de Usuario:** Proporcionar una interfaz fluida que cargue contenido a medida que el usuario lo necesita (ej. scroll infinito).

**Decisi√≥n:**
Paginaci√≥n de Datos en la API + Caching de Datos Agregados.

**Sustento:**
Esta combinaci√≥n ofrece una mejora dr√°stica del rendimiento con un esfuerzo razonable. La **paginaci√≥n** es una pr√°ctica est√°ndar y f√°cil de implementar que resuelve el problema de la carga masiva de datos. A√±adir una **cach√©** para los datos agregados reduce a√∫n m√°s la carga en la base de datos, garantizando que incluso las p√°ginas m√°s populares se mantengan r√°pidas y responsivas.

---

## M√≥dulo 06: An√°lisis de Datos y Reportes

## Escenario 1: Optimizaci√≥n de Consultas Hist√≥ricas

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-ADR-07 | Rendimiento | Un analista ejecuta una consulta sobre datos de ventas de juegos retro de hace 3 a√±os. | Analista de Datos / Herramienta de BI | Data Lake / Data Warehouse | Producci√≥n | El motor de consultas solo escanea los bloques de datos relevantes, ignorando el resto del historial. | Latencia de consulta reducida en 80%. |

- Aplica t√©cnica de **Particionamiento y Sharding** con las siguientes alternativas:
  1. Almacenar todos los datos en una **Base de datos √∫nica** (Tabla monol√≠tica).
  2. Aplicar **Particionamiento por Tiempo/ID**.

### **T√°ctica Elegida**
**Particionamiento por Tiempo/ID**

**Contexto:**
El volumen de datos hist√≥ricos (transacciones, rese√±as) crece constantemente. Si no se estructura la data, el costo y el tiempo de ejecuci√≥n (latencia) de las consultas aumentan linealmente. Para **GameVault**, es vital acelerar las consultas sobre **tendencias retro** espec√≠ficas de un periodo.

**Alternativas:**
1. **Base de datos √∫nica:**
   - La consulta tiene que escanear todo el dataset (Full Scan) cada vez.
   - Rendimiento pobre a escala de petabytes.

2. **Particionamiento por Tiempo/ID:**
   - Los datos se dividen f√≠sicamente en segmentos (particiones) basados en una columna clave (ej. fecha, consola). 
   - La consulta se dirige solo a la partici√≥n necesaria, minimizando I/O.

**Criterios de elecci√≥n:**
- **Eficiencia de Costos:** Se reduce el volumen de datos escaneados y el costo asociado en plataformas Cloud.
- **Rendimiento:** Disminuci√≥n dr√°stica de la latencia para las consultas de rango (hist√≥ricas).

**Decisi√≥n:**
Se aplica **Particionamiento por Tiempo/ID** en el Data Lake para optimizar las consultas hist√≥ricas.

**Sustento:**
El **Particionamiento** es fundamental para el **Rendimiento** de los sistemas de Big Data. Al estructurar la data por fecha, garantizamos que los *scripts* de **Python** que analizan periodos espec√≠ficos (ej. √∫ltimo trimestre) solo lean el subconjunto de datos necesario, haciendo la carga y el procesamiento mucho m√°s r√°pidos.


## Escenario 2: Procesamiento de Alto Volumen

| **Cod Escenario** | **Atributo de Calidad** | **Est√≠mulo** | **Fuente del Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|---|---|---|---|---|---|---|---|
| ESC-ADR-08 | Rendimiento | Ejecuci√≥n semanal de un modelo de machine learning (ML) para predecir precios de art√≠culos raros. | Script de Python / Tarea programada | Cluster de Procesamiento | Producci√≥n | El sistema ejecuta la tarea de procesamiento masivo en paralelo en m√∫ltiples nodos. | Tiempo de ejecuci√≥n de la tarea ML < 30 minutos. |

- Aplica t√©cnica de **Computaci√≥n Distribuida (PySpark)** con las siguientes alternativas:
  1. Uso de un **Servidor de procesamiento √∫nico** (Pandas en una sola m√°quina).
  2. Uso de un **Cluster Apache Spark/Databricks (usando PySpark)**.

### **T√°ctica Elegida**
**Cluster Apache Spark/Databricks (usando PySpark)**

**Contexto:**
El an√°lisis de **Big Data** para tareas intensivas (como el entrenamiento de modelos de ML o la manipulaci√≥n de terabytes de data con **Pandas**) no puede ser manejado por un √∫nico servidor debido a las limitaciones de memoria. El procesamiento debe ser **paralelo**.

**Alternativas:**
1. **Servidor de procesamiento √∫nico:**
   - R√°pido solo para datasets peque√±os (lo que cabe en la RAM).
   - Falla con *out-of-memory errors* al escalar.

2. **Cluster Apache Spark/Databricks (usando PySpark):**
   - Permite dividir el dataset en trozos y procesar cada uno en un nodo diferente. 
   - **PySpark** permite escribir la l√≥gica en **Python** (cumpliendo la restricci√≥n de lenguaje) mientras aprovecha el poder de la computaci√≥n distribuida.

**Criterios de elecci√≥n:**
- **Escalabilidad del Proceso:** Capacidad de procesar petabytes de datos eficientemente.
- **Restricci√≥n de Lenguaje:** Cumplir con la obligatoriedad de usar **Python** para el desarrollo.

**Decisi√≥n:**
Se utiliza **Cluster Apache Spark/Databricks (usando PySpark)** para el procesamiento de Big Data con el lenguaje Python.

**Sustento:**
El **Rendimiento** de los an√°lisis complejos se asegura mediante la **Computaci√≥n Distribuida**. Al utilizar **PySpark**, garantizamos que los desarrolladores de **Python** puedan aplicar las librer√≠as **Pandas/NumPy** a grandes conjuntos de datos, ejecutando las tareas de an√°lisis y ML de forma r√°pida y escalable.

---

[‚¨ÖÔ∏è Anterior](../5.7.3/5.7.3.md) | [üè† Home](../../../README.md) | [Siguiente ‚û°Ô∏è](../5.7.5/5.7.5.md)
