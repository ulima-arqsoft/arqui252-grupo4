> [8. Aplicaci√≥n de Patrones Arquitecturales](../../8.md) ‚Ä∫ [8.7. Listado Consolidado](../8.7.md) ‚Ä∫ [8.7.4. Patrones Cloud](8.7.4.md)

# 8.7.4. Patrones Cloud

## **01: M√≥dulo: Carrito de Compras y Pedidos**

---

**T√≠tulo:**
Optimizaci√≥n de lecturas mediante Patr√≥n Cache-Aside (Redis)

**Contexto:**
El cat√°logo recibe miles de consultas repetitivas (ej. "Juegos de Mario Bros"). Consultar `Elasticsearch` o `PostgreSQL` para cada repetici√≥n es ineficiente y costoso. Se requiere una estrategia para reducir la latencia y la carga en la base de datos (`ESC-CP 3`).

**Alternativas:**

  * **Patr√≥n Cache-Aside (Lazy Loading):**

      * La aplicaci√≥n (`Servicio de Cat√°logo`) verifica primero en `Redis`. Si no est√°, consulta a la BD y guarda el resultado en `Redis` para la pr√≥xima vez.
      * **Ventaja:** Solo se cachean los datos que realmente se piden. Resiliente a fallos de cach√© (si Redis cae, se va a la BD).

  * **Patr√≥n Write-Through:**

      * La cach√© se actualiza cada vez que se escribe un dato en la BD.
      * **Desventaja:** Datos que nunca se leen ocupan espacio en memoria (ineficiente para cat√°logos grandes con "long tail").

**Decisi√≥n:**
Se adopta el patr√≥n **Cache-Aside** utilizando `Redis`.

**Sustento:**
Implementa la t√°ctica `ESC-CP 3`. Reduce dr√°sticamente la latencia de lectura para b√∫squedas populares y protege al cl√∫ster de `Elasticsearch` de picos de tr√°fico.


## **03: M√≥dulo: Carrito de Compras y Pedidos**

---

**T√≠tulo:**
Escalabilidad El√°stica del Servicio de Carrito y Pedidos (Patr√≥n Horizontal Pod Autoscaler)

**Contexto:**
El Servicio de Carrito y Pedidos (M√≥dulo 3) experimentar√° una carga de trabajo variable. Durante eventos de alta demanda (ej. lanzamientos de juegos, ofertas de Black Friday), la creaci√≥n de pedidos (RF-04) puede aumentar dr√°sticamente. Necesitamos una estrategia para manejar estos picos de carga sin degradar el rendimiento y cumpliendo con la restricci√≥n de usar Kubernetes.

**Alternativas:**

* **Patr√≥n de Escalado Horizontal Autom√°tico (HPA):**
    * Utilizar el Horizontal Pod Autoscaler (HPA) de Kubernetes. Este patr√≥n cloud monitoriza el uso de CPU/Memoria del servicio CCP.
    * Cuando la carga supera un umbral (ej. 80% CPU), K8s autom√°ticamente despliega nuevas r√©plicas (pods) del Servicio CCP para distribuir la carga.
    * Ventaja: Escalabilidad el√°stica y autom√°tica. Se alinea con la t√°ctica ESC-CCP-13.
    * Ventaja: Eficiente en costos (solo usa los recursos necesarios).

* **Escalado Vertical Manual (Sobre-aprovisionamiento):**
    * Asignar permanentemente una gran cantidad de recursos (ej. 8 CPUs y 16GB de RAM) al Servicio CCP, esperando que sea suficiente para manejar el pico de carga.
    * Ventaja: Simple de configurar (no hay automatizaci√≥n).
    * Desventaja: Ineficiente y costoso (paga por recursos no utilizados el 99% del tiempo).
    * Desventaja: Si el pico supera lo provisionado, el servicio falla.

**Criterios de elecci√≥n:**

* **Rendimiento:** Mantener tiempos de respuesta bajos (< 5s) durante picos de carga, como define el escenario ESC-08.
* **Disponibilidad:** Asegurar que el servicio no se caiga por exceso de solicitudes.
* **Costo-Eficiencia:** Evitar pagar por recursos de c√≥mputo innecesarios.
* **Cumplimiento de T√°cticas:** Implementar la t√°ctica ESC-CCP-13.

**Decisi√≥n:**
Se adopta el patr√≥n cloud Horizontal Pod Autoscaler (HPA) de Kubernetes para el Servicio de Carrito y Pedidos (CCP).

**Sustento:**
Esta es la implementaci√≥n directa de la t√°ctica ESC-CCP-13: Auto Scaling con Kubernetes HPA. Es la √∫nica alternativa que garantiza el rendimiento y la disponibilidad (ESC-08) durante picos de demanda de forma el√°stica y eficiente en costos, aprovechando al m√°ximo la plataforma de Kubernetes exigida por las restricciones.

## **04: M√≥dulo: Sistema de Pagos**

---

**T√≠tulo:**
Fiabilidad de Pagos con Colas (Patr√≥n Queue-Based Load Leveling / Reintentos)

**Contexto:**
El Servicio de Pagos (M√≥dulo 4) interact√∫a con un sistema externo (Culqi). Los sistemas externos pueden fallar intermitentemente (ej. una falla de red de 5 segundos). Si fallamos al notificar a Culqi o al procesar un webhook, podr√≠amos perder una transacci√≥n. Necesitamos un patr√≥n cloud que asegure la Disponibilidad y la fiabilidad.

**Alternativas:**

* **Patr√≥n de Cola de Mensajes (RabbitMQ):**
    * Implementar la t√°ctica ESC-SP-02: Reintentos con Fila de Mensajes (RabbitMQ).
    * Si una llamada s√≠ncrona a Culqi falla, en lugar de devolver un error 500, el Servicio de Pagos (SP) pone la solicitud en una cola de RabbitMQ.
    * Un "worker" separado consume de la cola y reintenta la operaci√≥n, asegurando que el pago eventualmente se procese.
    * Ventaja: Alta disponibilidad y fiabilidad. El sistema "absorbe" fallos temporales.

* **Reintentos S√≠ncronos (Simple Retry):**
    * En la misma llamada HTTP, si la conexi√≥n con Culqi falla, hacer un bucle y reintentar 3 veces antes de rendirse.
    * Ventaja: Simple de implementar.
    * Desventaja: Mantiene al usuario esperando (aumenta la latencia).
    * Desventaja: Si el fallo dura m√°s de 10 segundos, el Servicio de Pedidos (CCP) recibir√° un timeout y el pago se perder√°.

**Criterios de elecci√≥n:**

* **Disponibilidad:** Cumplir con la t√°ctica ESC-SP-02 para manejar fallos intermitentes.
* **Fiabilidad:** Asegurar que ning√∫n pago se pierda por un fallo temporal de la red.
* **Rendimiento (Usuario):** No bloquear al usuario mientras el sistema reintenta operaciones de backend.

**Decisi√≥n:**
Se adopta el Patr√≥n de Cola de Mensajes (RabbitMQ) para manejar operaciones cr√≠ticas y reintentos en el Servicio de Pagos (SP).

**Sustento:**
Esta decisi√≥n implementa directamente la t√°ctica de disponibilidad ESC-SP-02 definida para el M√≥dulo 4. Es la √∫nica alternativa que garantiza la fiabilidad de las transacciones de pago ante fallos de red intermitentes. Al usar RabbitMQ, el Servicio de Pagos puede dar una respuesta r√°pida al CCP (ej. "Pago en procesamiento") mientras la cola gestiona los reintentos en segundo plano, mejorando la resiliencia del sistema.  


## 06: M√≥dulo: An√°lisis de Datos y Reportes

---

**T√≠tulo:**
Nivelaci√≥n de carga mediante Colas (Queue-Based Load Leveling)

**Contexto:**
El sistema puede generar picos masivos de eventos (ej. miles de "clicks" o "vistas de producto" por segundo en Black Friday). Si el `Servicio de An√°lisis` intentara procesar esto en tiempo real sincr√≥nicamente, colapsar√≠a. Se necesita proteger el servicio de an√°lisis de estos picos (`ESC-20`).

**Alternativas:**

  * **Patr√≥n Queue-Based Load Leveling:**

      * Usar `Kafka` como un buffer intermedio. Los productores escriben a la velocidad que necesitan; el consumidor (`Servicio An√°lisis`) lee a su propio ritmo.
      * **Ventaja:** Suaviza los picos de carga. No se pierden datos si el consumidor es lento.

  * **Procesamiento S√≠ncrono:**

      * Enviar los datos directamente al servicio de an√°lisis.
      * **Desventaja:** Si el tr√°fico supera la capacidad de procesamiento, el sistema falla o rechaza peticiones.

**Decisi√≥n:**
Se adopta el patr√≥n **Queue-Based Load Leveling** utilizando **Kafka**.

**Sustento:**
Es la implementaci√≥n directa de la arquitectura basada en eventos definida para el M√≥dulo 6. Permite que el sistema soporte cargas masivas de eventos (`ESC-20`) sin necesidad de sobredimensionar la infraestructura de an√°lisis, ya que Kafka act√∫a como amortiguador.

---

[‚¨ÖÔ∏è Anterior](../8.7.3/8.7.3.md) | [üè† Home](../../../README.md)